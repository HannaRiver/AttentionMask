name: 'Single Shot Mask - ResNet 50'


layer {
  name: "gt_data"
  type: "ImageData"
  top: "gt"
  top: "blub"
  
  include {
    phase: TRAIN
  }
transform_param {
scale: 0.0039215684
}

 image_data_param {
    source: "/data2/fastMaskTest/buAttMasks/gtList.txt"
    batch_size: 1
    is_color: false
    shuffle: false
new_width : 25
  new_height : 25 
  }
}


layer {
  name: "image_data"
  type: "ImageData"
  top: "data"
  top: "bla"
  
  include {
    phase: TRAIN
  }
transform_param {
scale: 0.0039215684
}
  image_data_param {
    source: "/data2/fastMaskTest/images/imgList.txt"
    batch_size: 1
    is_color: true
    shuffle: false
new_width : 200
  new_height : 200
  }
}


layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_out"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
  }
}

layer {
  name: "relu:conv1"
  type: "ReLU"
  bottom: "conv1_out"
  top: "conv1_relu"
}

layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_relu"
  top: "conv2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
  }
}

layer {
  name: "relu:conv2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2_relu"
}

layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2_relu"
  top: "conv3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
  }
}

layer {
  name: "relu:conv3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3_relu"
}


layer {
  name: "1D_att"
  type: "Convolution"
  bottom: "conv3_relu"
  top: "flatten_att"
  convolution_param {
    num_output: 625
bias_term : false
    pad: 0
    kernel_size: 25
    stride: 1
  }
}
layer {
  name: "bn_1D_att"
  type: "BatchNorm"
  bottom: "flatten_att"
  top: "flatten_att"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_1D_att"
  type: "Scale"
  bottom: "flatten_att"
  top: "flatten_att"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu:1D_att"
  type: "ReLU"
  bottom: "1D_bu_att"
  top: "1D_bu_att"
}


#layer { name: 'att' type: 'InnerProduct' bottom: 'conv3_relu' top: 'flatten_att' 
#  inner_product_param { num_output: 625 } }#

layer {
  name: "atts_reshape" type: "Reshape" bottom: "flatten_att" top: "1D_bu_att"
  reshape_param { shape { dim: -1 dim: 1 dim: 25, dim: 25 } }
}


layer { name: 'seg' type: 'Sigmoid' bottom: '1D_bu_att' top: 'mask' }

layer {
  name: "silence"
  type: "Silence"
  bottom: "mask"
}

layer { name: "loss_bu_att" type: "NormalizedSigmoidCrossEntropyLoss" bottom: "1D_bu_att" bottom: "gt" propagate_down: true propagate_down: false top: "loss_bu_atts" loss_weight: 1}
#layer { name: "loss_bu_att" type: "EuclideanLoss" bottom: "mask" bottom: "bu_att_mask" propagate_down: true propagate_down: false top: "loss_bu_atts" loss_weight: 1}
#layer { name: "loss_bu_att" type: "EuclideanLoss" bottom: "mask" bottom: "gt" propagate_down: true propagate_down: false top: "loss" loss_weight: 1}

